{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (year, month, dayofmonth, hour, weekofyear, \n",
    "                                   date_format, udf, col)\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-01-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-02-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-03-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-04-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-05-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-06-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-07-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-08-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-09-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-10-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-11-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-12-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-13-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-14-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-15-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-16-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-17-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-18-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-19-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-20-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-21-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-22-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-23-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-24-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-25-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-26-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-27-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-28-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-29-events.json')\n",
      "s3.ObjectSummary(bucket_name='udacity-dend', key='log_data/2018/11/2018-11-30-events.json')\n"
     ]
    }
   ],
   "source": [
    "# import boto3\n",
    "# s3 = boto3.resource('s3', aws_access_key_id=os.environ['AWS_ACCESS_KEY_ID'], aws_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY'])\n",
    "# my_bucket = s3.Bucket('udacity-dend')\n",
    "\n",
    "# i=0\n",
    "# for my_bucket_object in my_bucket.objects.filter(Prefix='log_data/').all(): #.all()\n",
    "#     i+=1\n",
    "#     print(my_bucket_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Song Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- num_songs: integer (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n",
      "+---------+------------------+---------------+----------------+-----------------+--------------------+------------------+--------------------+---------+----+\n",
      "|num_songs|         artist_id|artist_latitude|artist_longitude|  artist_location|         artist_name|           song_id|               title| duration|year|\n",
      "+---------+------------------+---------------+----------------+-----------------+--------------------+------------------+--------------------+---------+----+\n",
      "|        1|ARDR4AC1187FB371A1|           null|            null|                 |Montserrat Caball...|SOBAYLL12A8C138AF9|Sono andati? Fing...|511.16363|   0|\n",
      "|        1|AREBBGV1187FB523D2|           null|            null|      Houston, TX|Mike Jones (Featu...|SOOLYAZ12A6701F4A6|Laws Patrolling (...|173.66159|   0|\n",
      "|        1|ARMAC4T1187FB3FA4C|       40.82624|       -74.47995|Morris Plains, NJ|The Dillinger Esc...|SOBBUGU12A8C13E95D|Setting Fire to S...|207.77751|2004|\n",
      "|        1|ARPBNLO1187FB3D52F|       40.71455|       -74.00712|     New York, NY|            Tiny Tim|SOAOIBZ12AB01815BE|I Hold Your Hand ...| 43.36281|2000|\n",
      "|        1|ARDNS031187B9924F0|       32.67828|       -83.22295|          Georgia|          Tim Wilson|SONYPOM12A8C13B2D7|I Think My Wife I...|186.48771|2005|\n",
      "+---------+------------------+---------------+----------------+-----------------+--------------------+------------------+--------------------+---------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType, LongType, TimestampType\n",
    "\n",
    "song_schema = StructType([\n",
    "    StructField(\"num_songs\",        IntegerType()),\n",
    "    StructField(\"artist_id\",        StringType()),\n",
    "    StructField(\"artist_latitude\",  DoubleType()),\n",
    "    StructField(\"artist_longitude\", DoubleType()),\n",
    "    StructField(\"artist_location\",  StringType()),\n",
    "    StructField(\"artist_name\",      StringType()),\n",
    "    StructField(\"song_id\",          StringType()),\n",
    "    StructField(\"title\",            StringType()),\n",
    "    StructField(\"duration\",         DoubleType()),\n",
    "    StructField(\"year\",             IntegerType()),\n",
    "])\n",
    "\n",
    "song_data_df = spark.read.json(\"data/song_data/*/*/*/*.json\", schema=song_schema)\n",
    "song_data_df.printSchema()\n",
    "song_data_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- datetime: string (nullable = true)\n",
      "\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+-------------------+\n",
      "|     artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|                song|status|           ts|           userAgent|userId|           datetime|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+-------------------+\n",
      "|   Harmonia|Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|       Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|2018-11-15 00:30:26|\n",
      "|The Prodigy|Logged In|     Ryan|     M|            1|   Smith|260.07465| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|     The Big Gundown|   200|1542242481796|\"Mozilla/5.0 (X11...|    26|2018-11-15 00:41:21|\n",
      "|      Train|Logged In|     Ryan|     M|            2|   Smith|205.45261| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|            Marry Me|   200|1542242741796|\"Mozilla/5.0 (X11...|    26|2018-11-15 00:45:41|\n",
      "|Sony Wonder|Logged In|   Samuel|     M|            0|Gonzalez|218.06975| free|Houston-The Woodl...|   PUT|NextSong|1.540492941796E12|      597|           Blackbird|   200|1542253449796|\"Mozilla/5.0 (Mac...|    61|2018-11-15 03:44:09|\n",
      "|  Van Halen|Logged In|    Tegan|     F|            2|  Levine|289.38404| paid|Portland-South Po...|   PUT|NextSong|1.540794356796E12|      602|Best Of Both Worl...|   200|1542260935796|\"Mozilla/5.0 (Mac...|    80|2018-11-15 05:48:55|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_unixtime, col\n",
    "\n",
    "log_schema = StructType([\n",
    "    StructField(\"artist\",        StringType()),\n",
    "    StructField(\"auth\",          StringType()),\n",
    "    StructField(\"firstName\",     StringType()),\n",
    "    StructField(\"gender\",        StringType()),\n",
    "    StructField(\"itemInSession\", LongType()),\n",
    "    StructField(\"lastName\",      IntegerType()),\n",
    "    StructField(\"length\",        DoubleType()),\n",
    "    StructField(\"level\",         StringType()),\n",
    "    StructField(\"location\",      StringType()),\n",
    "    StructField(\"method\",        StringType()),\n",
    "    StructField(\"page\",          StringType()),\n",
    "    StructField(\"registration\",  DoubleType()),\n",
    "    StructField(\"sessionId\",     DoubleType()),\n",
    "    StructField(\"song\",          StringType()),\n",
    "    StructField(\"status\",        IntegerType()),\n",
    "    StructField(\"ts\",            TimestampType()),\n",
    "    StructField(\"userAgent\",     IntegerType()),\n",
    "    StructField(\"userId\",        LongType()),\n",
    "])\n",
    "\n",
    "log_data_df = spark.read.json(\"data/log_data/*/*/*.json\")\n",
    "log_data_df = log_data_df.where(col(\"page\")==\"NextSong\")\n",
    "log_data_df = log_data_df.withColumn(\"datetime\", from_unixtime(col(\"ts\")/1000))\n",
    "log_data_df.printSchema()\n",
    "log_data_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Tables for SQL in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_data_df.createOrReplaceTempView(\"song_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "log_data_df.createOrReplaceTempView(\"log_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# songs = song_data_df.select(\"song_id\", \"title\", \"artist_id\", \"year\", \"duration\") \\\n",
    "#                     .where(\"song_id is not null\") \\\n",
    "#                     .dropDuplicates() \\\n",
    "#                     .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOBBXLX12A58A79DDA|Erica (2005 Digit...|AREDBBQ1187B98AFF5|   0|138.63138|\n",
      "|SOUDSGM12AC9618304|Insatiable (Instr...|ARNTLGG11E2835DDB9|   0|266.39628|\n",
      "|SOBCOSW12A8C13D398|  Rumba De Barcelona|AR7SMBG1187B9B9066|   0|218.38322|\n",
      "|SOZCTXZ12AB0182364|      Setanta matins|AR5KOSW1187FB35FF4|   0|269.58322|\n",
      "|SOBZBAZ12A6D4F8742|      Spanish Grease|AROUOZZ1187B9ABE51|1997|168.25424|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "           s.song_id   as song_id\n",
    "         , s.title     as title\n",
    "         , s.artist_id as artist_id\n",
    "         , s.year      as year\n",
    "         , s.duration  as duration\n",
    "    FROM song_data s\n",
    "    WHERE s.song_id IS NOT NULL\n",
    "\"\"\")\n",
    "songs.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# artists = song_data_df.select(\"artist_id\", F.col(\"artist_name\").alias(\"name\"), F.col(\"artist_location\").alias(\"location\"), \n",
    "#                               F.col(\"artist_latitude\").alias(\"latitude\"), F.col(\"artist_longitude\").alias(\"longitude\")) \\\n",
    "#                       .where(\"artist_id is not null\") \\\n",
    "#                       .dropDuplicates() \\\n",
    "#                       .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+---------------+--------+----------+\n",
      "|         artist_id|        name|       location|latitude| longitude|\n",
      "+------------------+------------+---------------+--------+----------+\n",
      "|ARPBNLO1187FB3D52F|    Tiny Tim|   New York, NY|40.71455| -74.00712|\n",
      "|ARBEBBY1187B9B43DB|   Tom Petty|Gainesville, FL|    null|      null|\n",
      "|AR0IAWL1187B9A96D0|Danilo Perez|         Panama|  8.4177| -80.11278|\n",
      "|ARMBR4Y1187B9990EB|David Martin|California - SF|37.77916|-122.42005|\n",
      "|ARD0S291187B9B7BF5|     Rated R|           Ohio|    null|      null|\n",
      "+------------------+------------+---------------+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "           s.artist_id        as artist_id\n",
    "         , s.artist_name      as name\n",
    "         , s.artist_location  as location\n",
    "         , s.artist_latitude  as latitude\n",
    "         , s.artist_longitude as longitude\n",
    "    FROM song_data s\n",
    "    WHERE s.artist_id IS NOT NULL\n",
    "\"\"\")\n",
    "artists.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     98|    Jordyn|   Powell|     F| free|\n",
      "|     34|    Evelin|    Ayala|     F| free|\n",
      "|     85|   Kinsley|    Young|     F| paid|\n",
      "|     38|    Gianna|    Jones|     F| free|\n",
      "|     85|   Kinsley|    Young|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "           e.userId    as user_id\n",
    "         , e.firstName as first_name\n",
    "         , e.lastName  as last_name\n",
    "         , e.gender    as gender\n",
    "         , e.level     as level\n",
    "    FROM log_data e\n",
    "    WHERE e.userId IS NOT NULL\n",
    "\"\"\")\n",
    "users.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|         start_time|hour|day|week|month|year|weekday|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-15 11:39:32|  11| 15|  46|   15|2018|   true|\n",
      "|2018-11-15 15:16:39|  15| 15|  46|   15|2018|   true|\n",
      "|2018-11-15 17:37:32|  17| 15|  46|   15|2018|   true|\n",
      "|2018-11-15 22:10:08|  22| 15|  46|   15|2018|   true|\n",
      "|2018-11-21 07:21:43|   7| 21|  47|   21|2018|   true|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour, dayofmonth, weekofyear, month, year, dayofweek\n",
    "\n",
    "time = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "           e.datetime           as start_time\n",
    "         , hour(datetime)       as hour\n",
    "         , day(datetime)        as day\n",
    "         , weekofyear(datetime) as week\n",
    "         , dayofmonth(datetime) as month\n",
    "         , year(datetime)       as year\n",
    "         , CASE WHEN dayofweek(datetime) in (1,7) THEN FALSE ELSE TRUE END as weekday\n",
    "    FROM log_data e\n",
    "    WHERE e.ts IS NOT NULL\n",
    "\"\"\")\n",
    "time.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Songplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "|songplay_id|         start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|\n",
      "+-----------+-------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "|          1|2018-11-21 21:56:47|     15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|\n",
      "+-----------+-------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower, monotonically_increasing_id\n",
    "\n",
    "songplay = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "           row_number() over (order by monotonically_increasing_id()) as songplay_id\n",
    "         , e.datetime  as start_time\n",
    "         , e.userId    as user_id\n",
    "         , e.level     as level\n",
    "         , s.song_id   as song_id\n",
    "         , s.artist_id as artist_id\n",
    "         , e.sessionId as session_id\n",
    "         , e.location  as location\n",
    "         , e.userAgent as user_agent\n",
    "    FROM log_data e\n",
    "    JOIN song_data s ON (\n",
    "        lower(e.artist) = lower(s.artist_name)\n",
    "        AND lower(e.song) = lower(s.title)\n",
    "        AND e.length = s.duration\n",
    "    )\n",
    "\"\"\")\n",
    "songplay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# songplay.withColumn(\"year\", year(\"start_time\")) \\\n",
    "#         .withColumn(\"month\", month(\"start_time\")) \\\n",
    "#         .write.partitionBy(\"year\", \"month\") \\\n",
    "#         .mode(\"overwrite\") \\\n",
    "#         .parquet(\"output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/opt/spark-2.4.3-bin-hadoop2.7/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-3be7a5a2-c478-4cab-9da5-6e25c136427e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;2.7.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-common;2.7.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-annotations;2.7.0 in central\n",
      "\tfound com.google.guava#guava;11.0.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound commons-cli#commons-cli;1.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.1.1 in central\n",
      "\tfound xmlenc#xmlenc;0.52 in central\n",
      "\tfound commons-httpclient#commons-httpclient;3.1 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.4 in central\n",
      "\tfound commons-io#commons-io;2.4 in central\n",
      "\tfound commons-net#commons-net;3.1 in central\n",
      "\tfound commons-collections#commons-collections;3.2.1 in central\n",
      "\tfound javax.servlet#servlet-api;2.5 in central\n",
      "\tfound org.mortbay.jetty#jetty;6.1.26 in central\n",
      "\tfound org.mortbay.jetty#jetty-util;6.1.26 in central\n",
      "\tfound com.sun.jersey#jersey-core;1.9 in central\n",
      "\tfound com.sun.jersey#jersey-json;1.9 in central\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
      "\tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.2.2 in central\n",
      "\tfound javax.xml.stream#stax-api;1.0-2 in central\n",
      "\tfound javax.activation#activation;1.1 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-jaxrs;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-xc;1.9.13 in central\n",
      "\tfound com.sun.jersey#jersey-server;1.9 in central\n",
      "\tfound asm#asm;3.2 in central\n",
      "\tfound log4j#log4j;1.2.17 in central\n",
      "\tfound net.java.dev.jets3t#jets3t;0.9.0 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.2.5 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.2.5 in central\n",
      "\tfound com.jamesmurty.utils#java-xmlbuilder;0.4 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound commons-configuration#commons-configuration;1.6 in central\n",
      "\tfound commons-digester#commons-digester;1.8 in central\n",
      "\tfound commons-beanutils#commons-beanutils;1.7.0 in central\n",
      "\tfound commons-beanutils#commons-beanutils-core;1.8.0 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.10 in central\n",
      "\tfound org.apache.avro#avro;1.7.4 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.3 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.0.4.1 in central\n",
      "\tfound org.apache.commons#commons-compress;1.4.1 in central\n",
      "\tfound org.tukaani#xz;1.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound com.google.code.gson#gson;2.2.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-auth;2.7.0 in central\n",
      "\tfound org.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.server#apacheds-i18n;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.api#api-asn1-api;1.0.0-M20 in central\n",
      "\tfound org.apache.directory.api#api-util;1.0.0-M20 in central\n",
      "\tfound org.apache.zookeeper#zookeeper;3.4.6 in central\n",
      "\tfound org.slf4j#slf4j-log4j12;1.7.10 in central\n",
      "\tfound io.netty#netty;3.6.2.Final in central\n",
      "\tfound org.apache.curator#curator-framework;2.7.1 in central\n",
      "\tfound org.apache.curator#curator-client;2.7.1 in central\n",
      "\tfound com.jcraft#jsch;0.1.42 in central\n",
      "\tfound org.apache.curator#curator-recipes;2.7.1 in central\n",
      "\tfound org.apache.htrace#htrace-core;3.1.0-incubating in central\n",
      "\tfound javax.servlet.jsp#jsp-api;2.1 in central\n",
      "\tfound jline#jline;0.9.94 in central\n",
      "\tfound junit#junit;4.11 in central\n",
      "\tfound org.hamcrest#hamcrest-core;1.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.2.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.2.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.2.3 in central\n",
      "\tfound com.amazonaws#aws-java-sdk;1.7.4 in central\n",
      "\tfound joda-time#joda-time;2.10.13 in central\n",
      "\t[2.10.13] joda-time#joda-time;[2.2,)\n",
      ":: resolution report :: resolve 4695ms :: artifacts dl 108ms\n",
      "\t:: modules in use:\n",
      "\tasm#asm;3.2 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk;1.7.4 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.2.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.2.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.2.3 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.2.4 from central in [default]\n",
      "\tcom.google.guava#guava;11.0.2 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcom.jamesmurty.utils#java-xmlbuilder;0.4 from central in [default]\n",
      "\tcom.jcraft#jsch;0.1.42 from central in [default]\n",
      "\tcom.sun.jersey#jersey-core;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-json;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-server;1.9 from central in [default]\n",
      "\tcom.sun.xml.bind#jaxb-impl;2.2.3-1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.3 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils;1.7.0 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils-core;1.8.0 from central in [default]\n",
      "\tcommons-cli#commons-cli;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.4 from central in [default]\n",
      "\tcommons-collections#commons-collections;3.2.1 from central in [default]\n",
      "\tcommons-configuration#commons-configuration;1.6 from central in [default]\n",
      "\tcommons-digester#commons-digester;1.8 from central in [default]\n",
      "\tcommons-httpclient#commons-httpclient;3.1 from central in [default]\n",
      "\tcommons-io#commons-io;2.4 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tcommons-net#commons-net;3.1 from central in [default]\n",
      "\tio.netty#netty;3.6.2.Final from central in [default]\n",
      "\tjavax.activation#activation;1.1 from central in [default]\n",
      "\tjavax.servlet#servlet-api;2.5 from central in [default]\n",
      "\tjavax.servlet.jsp#jsp-api;2.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.2.2 from central in [default]\n",
      "\tjavax.xml.stream#stax-api;1.0-2 from central in [default]\n",
      "\tjline#jline;0.9.94 from central in [default]\n",
      "\tjoda-time#joda-time;2.10.13 from central in [default]\n",
      "\tjunit#junit;4.11 from central in [default]\n",
      "\tlog4j#log4j;1.2.17 from central in [default]\n",
      "\tnet.java.dev.jets3t#jets3t;0.9.0 from central in [default]\n",
      "\torg.apache.avro#avro;1.7.4 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.4.1 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.1.1 from central in [default]\n",
      "\torg.apache.curator#curator-client;2.7.1 from central in [default]\n",
      "\torg.apache.curator#curator-framework;2.7.1 from central in [default]\n",
      "\torg.apache.curator#curator-recipes;2.7.1 from central in [default]\n",
      "\torg.apache.directory.api#api-asn1-api;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.api#api-util;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-i18n;2.0.0-M15 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;2.7.0 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-auth;2.7.0 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;2.7.0 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-common;2.7.0 from central in [default]\n",
      "\torg.apache.htrace#htrace-core;3.1.0-incubating from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.2.5 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.2.5 from central in [default]\n",
      "\torg.apache.zookeeper#zookeeper;3.4.6 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-jaxrs;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-xc;1.9.13 from central in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
      "\torg.hamcrest#hamcrest-core;1.3 from central in [default]\n",
      "\torg.mortbay.jetty#jetty;6.1.26 from central in [default]\n",
      "\torg.mortbay.jetty#jetty-util;6.1.26 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.10 from central in [default]\n",
      "\torg.slf4j#slf4j-log4j12;1.7.10 from central in [default]\n",
      "\torg.tukaani#xz;1.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.0.4.1 from central in [default]\n",
      "\txmlenc#xmlenc;0.52 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   70  |   1   |   0   |   0   ||   70  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-3be7a5a2-c478-4cab-9da5-6e25c136427e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 70 already retrieved (0kB/50ms)\n",
      "21/12/05 18:37:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "!spark-submit etl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "TABLE:  users\n",
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      "\n",
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     88|  Mohammad|Rodriguez|     M| free|\n",
      "|     88|  Mohammad|Rodriguez|     M| paid|\n",
      "|     11| Christian|   Porter|     F| free|\n",
      "|     75|    Joseph|Gutierrez|     M| free|\n",
      "|     77| Magdalene|   Herman|     F| free|\n",
      "|     69|  Anabelle|  Simpson|     F| free|\n",
      "|     53|   Celeste| Williams|     F| free|\n",
      "|     61|    Samuel| Gonzalez|     M| free|\n",
      "|      2|   Jizelle| Benjamin|     F| free|\n",
      "|     45|  Dominick|   Norris|     M| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "TABLE:  artists\n",
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|         artist_id|                name|            location|latitude|longitude|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "|ARMAC4T1187FB3FA4C|The Dillinger Esc...|   Morris Plains, NJ|40.82624|-74.47995|\n",
      "|AROUOZZ1187B9ABE51|         Willie Bobo|New York, NY [Spa...|40.79195|-73.94512|\n",
      "|ARI2JSK1187FB496EF|Nick Ingman;Gavyn...|     London, England|51.50632| -0.12714|\n",
      "|AREBBGV1187FB523D2|Mike Jones (Featu...|         Houston, TX|    null|     null|\n",
      "|ARD842G1187B997376|          Blue Rodeo|Toronto, Ontario,...|43.64856|-79.38533|\n",
      "|ARDR4AC1187FB371A1|Montserrat Caball...|                    |    null|     null|\n",
      "|AR47JEX1187B995D81|        SUE THOMPSON|          Nevada, MO|37.83721|-94.35868|\n",
      "|AR0RCMP1187FB3F427|    Billie Jo Spears|        Beaumont, TX|30.08615|-94.10158|\n",
      "|ARIG6O41187B988BDD|     Richard Souther|       United States|37.16793|-95.84502|\n",
      "|ARGSJW91187B9B1D6B|        JennyAnyKind|      North Carolina|35.21962|-80.01955|\n",
      "+------------------+--------------------+--------------------+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "TABLE:  songplays\n",
      "root\n",
      " |-- songplay_id: integer (nullable = true)\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- session_id: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- user_agent: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "+-----------+-------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|songplay_id|         start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|year|month|\n",
      "+-----------+-------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|          1|2018-11-21 21:56:47|     15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "+-----------+-------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "TABLE:  time\n",
      "root\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- weekday: boolean (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "+-------------------+----+---+----+-------+----+-----+\n",
      "|         start_time|hour|day|week|weekday|year|month|\n",
      "+-------------------+----+---+----+-------+----+-----+\n",
      "|2018-11-21 01:03:13|   1| 21|  47|   true|2018|   21|\n",
      "|2018-11-21 01:05:29|   1| 21|  47|   true|2018|   21|\n",
      "|2018-11-21 04:28:00|   4| 21|  47|   true|2018|   21|\n",
      "|2018-11-21 18:39:50|  18| 21|  47|   true|2018|   21|\n",
      "|2018-11-21 19:03:38|  19| 21|  47|   true|2018|   21|\n",
      "|2018-11-21 19:22:16|  19| 21|  47|   true|2018|   21|\n",
      "|2018-11-21 22:01:16|  22| 21|  47|   true|2018|   21|\n",
      "|2018-11-14 05:45:26|   5| 14|  46|   true|2018|   14|\n",
      "|2018-11-14 05:57:40|   5| 14|  46|   true|2018|   14|\n",
      "|2018-11-14 08:14:32|   8| 14|  46|   true|2018|   14|\n",
      "+-------------------+----+---+----+-------+----+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "TABLE:  songs\n",
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      "\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|           song_id|               title| duration|year|         artist_id|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|SOAOIBZ12AB01815BE|I Hold Your Hand ...| 43.36281|2000|ARPBNLO1187FB3D52F|\n",
      "|SONYPOM12A8C13B2D7|I Think My Wife I...|186.48771|2005|ARDNS031187B9924F0|\n",
      "|SODREIN12A58A7F2E5|A Whiter Shade Of...|326.00771|   0|ARLTWXK1187FB5A3F8|\n",
      "|SOYMRWW12A6D4FAB14|The Moon And I (O...| 267.7024|   0|ARKFYS91187B98E58F|\n",
      "|SOWQTQZ12A58A7B63E|Streets On Fire (...|279.97995|   0|ARPFHN61187FB575F6|\n",
      "|SOUDSGM12AC9618304|Insatiable (Instr...|266.39628|   0|ARNTLGG11E2835DDB9|\n",
      "|SOPEGZN12AB0181B3D|Get Your Head Stu...| 45.66159|   0|AREDL271187FB40F44|\n",
      "|SOBBUGU12A8C13E95D|Setting Fire to S...|207.77751|2004|ARMAC4T1187FB3FA4C|\n",
      "|SOBAYLL12A8C138AF9|Sono andati? Fing...|511.16363|   0|ARDR4AC1187FB371A1|\n",
      "|SOOLYAZ12A6701F4A6|Laws Patrolling (...|173.66159|   0|AREBBGV1187FB523D2|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for table in os.listdir(\"output\"):\n",
    "    print(120*\"-\")\n",
    "    print(\"TABLE: \",table)\n",
    "    df_etl = spark.read.parquet(\"output/\" + str(table))\n",
    "    df_etl.printSchema()\n",
    "    df_etl.show(10)\n",
    "    \n",
    "    print(120*\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0f97e6508b2a63d7812d2d3d1884e63b5817ddcd7103f02161aa1e61d2339ee"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
